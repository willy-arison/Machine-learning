{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 1095715,
          "sourceType": "datasetVersion",
          "datasetId": 612351
        }
      ],
      "dockerImageVersionId": 31041,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "transformer",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/willy-arison/Machine-learning/blob/master/transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "amananandrai_ag_news_classification_dataset_path = kagglehub.dataset_download('amananandrai/ag-news-classification-dataset')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "y2ohIbxgGwV4"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# requirements\n",
        "! pip install tokenizers datasets transformers[torch]\n",
        "! pip install lightning"
      ],
      "metadata": {
        "trusted": true,
        "id": "Ney6p7EWGwV5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "import torch\n",
        "from torch import nn"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-11T12:09:59.83906Z",
          "iopub.execute_input": "2025-06-11T12:09:59.839832Z",
          "iopub.status.idle": "2025-06-11T12:10:03.203059Z",
          "shell.execute_reply.started": "2025-06-11T12:09:59.839799Z",
          "shell.execute_reply": "2025-06-11T12:10:03.202289Z"
        },
        "id": "Bwoz4BHGGwV7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **GHF activation**"
      ],
      "metadata": {
        "id": "hpPHzA7HGwV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import Function\n",
        "\n",
        "class ActGHFFunction(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, s, t, m1, m2):\n",
        "\n",
        "        # Forward computation\n",
        "        num = 1 + m1 * t\n",
        "        den = 1 + m2 * t * torch.exp(-s/t)\n",
        "        output = num / den\n",
        "\n",
        "        # Save for backward pass\n",
        "        ctx.save_for_backward(t, m1, output)\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        t, m1, output = ctx.saved_tensors\n",
        "        grad_s = (1/t) * output * (1 - (1/(1 + m1*t)) * output)\n",
        "        return grad_output * grad_s, None, None, None\n",
        "\n",
        "class ActGHF(nn.Module):\n",
        "    def __init__(self, t=0.5, m1=-1.001, m2=50):\n",
        "        super(ActGHF, self).__init__()\n",
        "        self.register_buffer('t', torch.tensor(float(t)))\n",
        "        self.register_buffer('m1', torch.tensor(float(m1)))\n",
        "        self.register_buffer('m2', torch.tensor(float(m2)))\n",
        "\n",
        "    def forward(self, s):\n",
        "        return ActGHFFunction.apply(s, self.t, self.m1, self.m2)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-11T12:10:08.94624Z",
          "iopub.execute_input": "2025-06-11T12:10:08.946628Z",
          "iopub.status.idle": "2025-06-11T12:10:08.953654Z",
          "shell.execute_reply.started": "2025-06-11T12:10:08.946606Z",
          "shell.execute_reply": "2025-06-11T12:10:08.952889Z"
        },
        "id": "TgmFv81yGwV_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Implement Transformer layer**\n",
        "* Transformer layer consists of *Multi-Head Attention* or *Single Head Attention*\n",
        "\n",
        "#### **Implement Transformer Encoder Layer**\n",
        "* It consists of:\n",
        "> * A self-Attention mechanism to capture long-range dependencies\n",
        "> * Fully connected layers to transform representations\n",
        "> * Layer normalization to stabilize training\n",
        "> * Residual connections to improve gradient flow and prevent vanishing gradient\n",
        "\n",
        "\n",
        "#### **Implement Transformer Network**\n",
        "* The full transformer network consists of:\n",
        "> * Embedding Module: transform input tokens into dense vectors\n",
        "> * Transformer Layers: A stack of transformer encoder layer\n",
        "> * Classification head: Processes the output of the transformer layers into produce prediction"
      ],
      "metadata": {
        "id": "Bcg8tvRzGwWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SingleHeadAttention(nn.Module):\n",
        "    def __init__(self, embed_dim):\n",
        "        super().__init__()\n",
        "        self.W_q = nn.Linear(embed_dim, embed_dim, bias=False)\n",
        "        self.W_k = nn.Linear(embed_dim, embed_dim, bias=False)\n",
        "        self.W_v = nn.Linear(embed_dim, embed_dim, bias=False)\n",
        "\n",
        "    def forward(self, x, attention_mask=None):\n",
        "        # x: [batch size, seq_length, embed_dim]\n",
        "        Q = self.W_q(x) # --> [batch size, seq_length, embed_dim]\n",
        "        K = self.W_k(x)\n",
        "        V = self.W_v(x)\n",
        "\n",
        "        # key dimension\n",
        "        dk = Q.shape[-1]\n",
        "\n",
        "        # Dot-products similarities\n",
        "        scores = Q @ K.transpose(1, 2) # --> [batch size, seq_length, seq_length]\n",
        "\n",
        "        # scaled by dimension\n",
        "        scores = scores / dk ** 0.5\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            mask = attention_mask.float().masked_fill(attention_mask == 0, float('-inf'))\n",
        "            scores = scores + mask.unsqueeze(1)\n",
        "\n",
        "        # transform into probabilities\n",
        "        scores = nn.Softmax(dim=2)(scores)\n",
        "\n",
        "        # update x\n",
        "        x = scores @ V # --> [batch_size, seq_length, embed_dim]\n",
        "\n",
        "        return x\n",
        "\n",
        "class TransformerEncoderLayer(nn.Module):\n",
        "    def __init__(self, embed_dim, activation_fn=nn.ReLU()):\n",
        "        super().__init__()\n",
        "        self.attention = SingleHeadAttention(embed_dim=embed_dim)\n",
        "\n",
        "        # layer normalization\n",
        "        self.layer_norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.layer_norm2 = nn.LayerNorm(embed_dim)\n",
        "\n",
        "        # fully connected layer\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Linear(embed_dim, embed_dim),\n",
        "            activation_fn,\n",
        "            nn.Linear(embed_dim, embed_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, attention_mask=None):\n",
        "        x = x + self.attention(self.layer_norm1(x), attention_mask)\n",
        "        x = x + self.fc_layer(self.layer_norm2(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "import math\n",
        "\n",
        "class Embedding(nn.Module):\n",
        "    def __init__(self, embed_dim, vocab_size, seq_length):\n",
        "        super().__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.seq_length = seq_length\n",
        "\n",
        "        # Token embeddings\n",
        "        self.embed_token = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embed_dim)\n",
        "\n",
        "        # positional encodings\n",
        "        self.register_buffer('positional_encodings', self._get_cosine_positional_encodings())\n",
        "\n",
        "    def _get_cosine_positional_encodings(self):\n",
        "        position = torch.arange(self.seq_length).unsqueeze(1)  # [seq_length, 1]\n",
        "        div_term = torch.exp(torch.arange(0, self.embed_dim, 2) * (-math.log(10000.0) / self.embed_dim))\n",
        "\n",
        "        encodings = torch.zeros(self.seq_length, self.embed_dim)\n",
        "        encodings[:, 0::2] = torch.sin(position * div_term)  # even indices: sin\n",
        "        encodings[:, 1::2] = torch.cos(position * div_term)  # odd indices: cos\n",
        "\n",
        "        return encodings  # [seq_length, embed_dim]\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x --> [batch_size, seq_length]\n",
        "        x = self.embed_token(x)  # [batch_size, seq_length, embed_dim]\n",
        "\n",
        "        # Add positional encodings\n",
        "        x = x + self.positional_encodings[:x.size(1), :]  # [batch_size, seq_length, embed_dim]\n",
        "\n",
        "        return x\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, embed_dim, vocab_size, seq_length=5, num_layers=2, num_classes=2, activation_fn=nn.ReLU()):\n",
        "        super().__init__()\n",
        "\n",
        "        # embedding module\n",
        "        self.embed = Embedding(embed_dim=embed_dim, vocab_size=vocab_size, seq_length=seq_length)\n",
        "        # encoder layers\n",
        "        self.encoder_layers = nn.ModuleList([\n",
        "            TransformerEncoderLayer(embed_dim=embed_dim, activation_fn=activation_fn) for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Linear(embed_dim, num_classes),\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x, attention_mask=None):\n",
        "        x = self.embed(x) # --> [batch size, seq_length, embed_dim]\n",
        "\n",
        "        for layer in self.encoder_layers:\n",
        "            x = layer(x, attention_mask) # --> [batch size, seq_length, embed_dim]\n",
        "\n",
        "        # for classification\n",
        "        x = x.mean(dim=1)  # --> [batch size, embed_dim]\n",
        "        x = self.fc_layer(x)  # --> [batch size, num_classes]\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-11T12:10:14.283243Z",
          "iopub.execute_input": "2025-06-11T12:10:14.283546Z",
          "iopub.status.idle": "2025-06-11T12:10:14.297081Z",
          "shell.execute_reply.started": "2025-06-11T12:10:14.283527Z",
          "shell.execute_reply": "2025-06-11T12:10:14.296279Z"
        },
        "id": "gzBwoZypGwWD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from datasets import Dataset\n",
        "\n",
        "\n",
        "train_df = pd.read_csv('/kaggle/input/ag-news-classification-dataset/train.csv')\n",
        "test_df = pd.read_csv('/kaggle/input/ag-news-classification-dataset/test.csv')\n",
        "\n",
        "train_df['text'] = train_df['Title'] + ': ' + train_df['Description']\n",
        "test_df['text'] = test_df['Title'] + ': ' + test_df['Description']\n",
        "train_df['Class Index'] = train_df['Class Index'] - train_df['Class Index'].min()\n",
        "test_df['Class Index'] = test_df['Class Index'] - test_df['Class Index'].min()\n",
        "\n",
        "train_df['label'] = train_df['Class Index']\n",
        "test_df['label'] = test_df['Class Index']\n",
        "\n",
        "\n",
        "train_df = train_df[['label', 'text']]\n",
        "test_df = test_df[['label', 'text']]\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "train_df.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-11T12:10:24.104827Z",
          "iopub.execute_input": "2025-06-11T12:10:24.105116Z",
          "iopub.status.idle": "2025-06-11T12:10:27.403285Z",
          "shell.execute_reply.started": "2025-06-11T12:10:24.105094Z",
          "shell.execute_reply": "2025-06-11T12:10:27.402693Z"
        },
        "id": "Kd-jRt9oGwWF",
        "outputId": "e659de1b-49da-4529-9300-3466f2af57da"
      },
      "outputs": [
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "   label                                               text\n0      2  Wall St. Bears Claw Back Into the Black (Reute...\n1      2  Carlyle Looks Toward Commercial Aerospace (Reu...\n2      2  Oil and Economy Cloud Stocks' Outlook (Reuters...\n3      2  Iraq Halts Oil Exports from Main Southern Pipe...\n4      2  Oil prices soar to all-time record, posing new...",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>Wall St. Bears Claw Back Into the Black (Reute...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Oil and Economy Cloud Stocks' Outlook (Reuters...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>Oil prices soar to all-time record, posing new...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 512\n",
        "batch_size = 128\n",
        "columns = ['text', 'label']"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-11T12:10:33.587638Z",
          "iopub.execute_input": "2025-06-11T12:10:33.58814Z",
          "iopub.status.idle": "2025-06-11T12:10:33.591429Z",
          "shell.execute_reply.started": "2025-06-11T12:10:33.588115Z",
          "shell.execute_reply": "2025-06-11T12:10:33.590855Z"
        },
        "id": "Fig6IOeKGwWG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def tokenize_function(sentence):\n",
        "    return tokenizer(\n",
        "        sentence[columns[0]],\n",
        "        padding='max_length',   # pad to max length\n",
        "        truncation=True,        # truncate if too large\n",
        "        max_length=max_length,\n",
        "    )\n",
        "\n",
        "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
        "tokenized_test = test_dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-11T12:10:38.734626Z",
          "iopub.execute_input": "2025-06-11T12:10:38.735102Z",
          "iopub.status.idle": "2025-06-11T12:11:45.750029Z",
          "shell.execute_reply.started": "2025-06-11T12:10:38.735079Z",
          "shell.execute_reply": "2025-06-11T12:11:45.749411Z"
        },
        "id": "ojgctmeZGwWI",
        "outputId": "82856695-66f0-46fe-b30a-dc496aab9463",
        "colab": {
          "referenced_widgets": [
            "9df89f861e414878b0a6d6c001a0686a",
            "6a1c7a3ba46c4d85aa601805ab619ab1",
            "eba54fa633774e0e8e4afccd8b70aa32",
            "15a6d5d4d34e4aa89184251f92b0518b",
            "f2662872f1514e97a831c1b326d968e5",
            "6750b3f32b5e4ee6847cf43b26e889bb"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9df89f861e414878b0a6d6c001a0686a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a1c7a3ba46c4d85aa601805ab619ab1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eba54fa633774e0e8e4afccd8b70aa32"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15a6d5d4d34e4aa89184251f92b0518b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/120000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2662872f1514e97a831c1b326d968e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/7600 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6750b3f32b5e4ee6847cf43b26e889bb"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, tokenized_data):\n",
        "        super().__init__()\n",
        "        self.tokenized_data = tokenized_data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tokenized_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(self.tokenized_data[idx][\"input_ids\"]),\n",
        "            \"attention_mask\": torch.tensor(self.tokenized_data[idx][\"attention_mask\"]),\n",
        "            \"labels\": torch.tensor(self.tokenized_data[idx][columns[1]]),\n",
        "        }\n",
        "\n",
        "# Create datasets\n",
        "train_pt = MyDataset(tokenized_train)\n",
        "test_pt = MyDataset(tokenized_test)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_pt,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=3\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_pt,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=3\n",
        ")\n",
        "\n",
        "\n",
        "# Example: Inspect a batch\n",
        "batch = next(iter(train_loader))\n",
        "print(\"Input IDs shape:\", batch[\"input_ids\"].shape)\n",
        "print(\"Labels:\", batch[\"labels\"])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-11T12:12:01.655602Z",
          "iopub.execute_input": "2025-06-11T12:12:01.656315Z",
          "iopub.status.idle": "2025-06-11T12:12:02.749809Z",
          "shell.execute_reply.started": "2025-06-11T12:12:01.65629Z",
          "shell.execute_reply": "2025-06-11T12:12:02.748973Z"
        },
        "id": "-geQDL8uGwWJ",
        "outputId": "619ed66d-c272-46cb-e7af-fdaaa03028df"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Input IDs shape: torch.Size([128, 512])\nLabels: tensor([1, 2, 1, 2, 0, 1, 3, 2, 2, 2, 0, 0, 3, 1, 2, 2, 0, 2, 3, 3, 1, 2, 0, 1,\n        3, 2, 2, 2, 2, 3, 3, 2, 0, 2, 1, 1, 1, 0, 0, 2, 2, 2, 0, 3, 0, 3, 3, 0,\n        0, 2, 0, 0, 2, 2, 3, 2, 0, 1, 1, 3, 1, 2, 2, 2, 0, 0, 2, 1, 1, 2, 3, 0,\n        3, 0, 0, 0, 1, 0, 3, 0, 3, 1, 3, 2, 0, 2, 1, 2, 3, 3, 0, 1, 2, 3, 2, 2,\n        1, 2, 3, 0, 2, 2, 2, 3, 2, 1, 2, 3, 3, 3, 3, 3, 3, 2, 0, 2, 0, 1, 2, 2,\n        0, 1, 3, 1, 3, 1, 3, 3])\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "def create_trainer(activation, max_epochs=5):\n",
        "    import logging\n",
        "    logging.getLogger(\"pytorch_lightning\").setLevel(logging.WARNING)\n",
        "\n",
        "    return pl.Trainer(\n",
        "        accelerator=\"gpu\",\n",
        "        strategy=\"auto\",\n",
        "        precision=\"16-mixed\",\n",
        "        devices=-1,\n",
        "        max_epochs=max_epochs,\n",
        "        logger=pl.loggers.TensorBoardLogger(f'logs/', name=activation),\n",
        "        callbacks=[\n",
        "            pl.callbacks.ModelCheckpoint(\n",
        "                monitor=\"val_acc\",                  # Metric to monitor\n",
        "                mode=\"max\",                         # Save when max accuracy\n",
        "                save_top_k=1,                       # Save only the best model\n",
        "                filename=\"{epoch}-{val_acc:.4f}\",   # Include accuracy in filename\n",
        "                save_last=True,                     # save final epoch\n",
        "                verbose=True                        # Print when new best model is saved\n",
        "            )\n",
        "        ],\n",
        "    )\n",
        "\n",
        "class Classifier(pl.LightningModule):\n",
        "    def __init__(self, model, num_classes):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.cross_entropy_loss = nn.CrossEntropyLoss()\n",
        "        self.test_accuracy = Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y, mask = batch['input_ids'], batch['labels'], batch['attention_mask']\n",
        "        logits = self.model(x, mask)\n",
        "        loss = self.cross_entropy_loss(logits, y)\n",
        "        self.log('train_loss', loss, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y, mask = batch['input_ids'], batch['labels'], batch['attention_mask']\n",
        "        logits = self.model(x, mask)\n",
        "        loss = self.cross_entropy_loss(logits, y)\n",
        "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
        "        self.log('val_loss', loss, prog_bar=True)\n",
        "        self.log('val_acc', acc, prog_bar=True)\n",
        "        return {'val_loss': loss, 'val_acc': acc}\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters()) # lr=0.005\n",
        "        return optimizer\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y, mask = batch['input_ids'], batch['labels'], batch['attention_mask']\n",
        "        preds = self.model(x, mask)  # Forward pass\n",
        "        self.test_accuracy(preds, y)  # Update accuracy metric\n",
        "        return preds\n",
        "\n",
        "    def on_test_epoch_end(self):\n",
        "        self.log(\"test_acc\", self.test_accuracy.compute(), prog_bar=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-11T12:12:36.747157Z",
          "iopub.execute_input": "2025-06-11T12:12:36.748203Z",
          "iopub.status.idle": "2025-06-11T12:12:36.757277Z",
          "shell.execute_reply.started": "2025-06-11T12:12:36.748174Z",
          "shell.execute_reply": "2025-06-11T12:12:36.756418Z"
        },
        "id": "F4lyuId9GwWK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = tokenizer.vocab_size\n",
        "seq_length = max_length\n",
        "embed_dim = 128\n",
        "epochs = 6\n",
        "classes = 4"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-11T12:12:40.758836Z",
          "iopub.execute_input": "2025-06-11T12:12:40.7592Z",
          "iopub.status.idle": "2025-06-11T12:12:40.764302Z",
          "shell.execute_reply.started": "2025-06-11T12:12:40.759178Z",
          "shell.execute_reply": "2025-06-11T12:12:40.763445Z"
        },
        "id": "oGG5ynE1GwWL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "activations = {\n",
        "    'relu': nn.ReLU(),\n",
        "    'mish': nn.Mish(),\n",
        "    'ghf': ActGHF(t=1, m1=5.5, m2=20)\n",
        "}"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-11T12:12:44.781186Z",
          "iopub.execute_input": "2025-06-11T12:12:44.781716Z",
          "iopub.status.idle": "2025-06-11T12:12:44.786544Z",
          "shell.execute_reply.started": "2025-06-11T12:12:44.781691Z",
          "shell.execute_reply": "2025-06-11T12:12:44.785458Z"
        },
        "id": "uRneeSN5GwWM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -r logs/\n",
        "\n",
        "for name, act in activations.items():\n",
        "    # model\n",
        "    model = Transformer(\n",
        "        embed_dim=embed_dim,\n",
        "        seq_length=seq_length,\n",
        "        vocab_size=vocab_size,\n",
        "        num_layers=1,\n",
        "        num_classes=classes,\n",
        "        activation_fn=act\n",
        "    )\n",
        "\n",
        "    # trainer\n",
        "    trainer = create_trainer(activation=name, max_epochs=epochs)\n",
        "    print(f'Train with {name} activation')\n",
        "\n",
        "    # classifier\n",
        "    classifier = Classifier(model, num_classes=classes)\n",
        "    trainer.fit(classifier, train_loader, test_loader)\n",
        "    trainer.test(classifier, test_loader)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-11T12:14:30.840628Z",
          "iopub.execute_input": "2025-06-11T12:14:30.840954Z",
          "iopub.status.idle": "2025-06-11T13:04:02.560529Z",
          "shell.execute_reply.started": "2025-06-11T12:14:30.84091Z",
          "shell.execute_reply": "2025-06-11T13:04:02.559581Z"
        },
        "id": "m_8TPzn4GwWM",
        "outputId": "00425e2e-bc6b-438d-fcf8-1d219ff9917c",
        "colab": {
          "referenced_widgets": [
            "",
            "ad10ad3cf4e945978cbf478bd9b19aa9",
            "88b5cdfdd2e242cbb984c500fba4ca88",
            "00514a2eba3844668b34c58bff080fab",
            "4b15bab57ba44a55b3902a6682df0d0f",
            "9fbc565cecec4febb90d834c1c33130e",
            "c2a11649af804d17971af3a0fd3a422d"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Train with relu activation\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad10ad3cf4e945978cbf478bd9b19aa9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Testing: |          | 0/? [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88b5cdfdd2e242cbb984c500fba4ca88"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9110526442527771    \u001b[0m\u001b[35m \u001b[0m│\n└───────────────────────────┴───────────────────────────┘\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9110526442527771     </span>│\n└───────────────────────────┴───────────────────────────┘\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Train with mish activation\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00514a2eba3844668b34c58bff080fab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Testing: |          | 0/? [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b15bab57ba44a55b3902a6682df0d0f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9136841893196106    \u001b[0m\u001b[35m \u001b[0m│\n└───────────────────────────┴───────────────────────────┘\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9136841893196106     </span>│\n└───────────────────────────┴───────────────────────────┘\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Train with ghf activation\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9fbc565cecec4febb90d834c1c33130e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Testing: |          | 0/? [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c2a11649af804d17971af3a0fd3a422d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9105263352394104    \u001b[0m\u001b[35m \u001b[0m│\n└───────────────────────────┴───────────────────────────┘\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9105263352394104     </span>│\n└───────────────────────────┴───────────────────────────┘\n</pre>\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "for name, act in activations.items():\n",
        "    file_name = glob.glob(f'/kaggle/working/logs/{name}/version_0/checkpoints/epoch*.ckpt')[0]\n",
        "    model = Transformer(\n",
        "        embed_dim=embed_dim,\n",
        "        seq_length=seq_length,\n",
        "        vocab_size=vocab_size,\n",
        "        num_layers=1,\n",
        "        num_classes=classes,\n",
        "        activation_fn=act\n",
        "    )\n",
        "    print(f'Accuracy with {name} activation')\n",
        "    classifier = Classifier.load_from_checkpoint(file_name, model=model, num_classes=classes)\n",
        "    trainer.test(classifier, test_loader)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-11T13:05:28.831936Z",
          "iopub.execute_input": "2025-06-11T13:05:28.832524Z",
          "iopub.status.idle": "2025-06-11T13:05:58.272347Z",
          "shell.execute_reply.started": "2025-06-11T13:05:28.832493Z",
          "shell.execute_reply": "2025-06-11T13:05:58.271636Z"
        },
        "id": "pdunoJqTGwWN",
        "outputId": "6aa37d3b-8ce7-4b01-f30f-e784c887f5f5",
        "colab": {
          "referenced_widgets": [
            "708a411492104992b645631de8a2cf10",
            "c9dfaa5faa8544bf90114ff0b289fd61",
            "1b012784e41641d9aac3938922c2c705"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Accuracy with relu activation\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Testing: |          | 0/? [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "708a411492104992b645631de8a2cf10"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9114473462104797    \u001b[0m\u001b[35m \u001b[0m│\n└───────────────────────────┴───────────────────────────┘\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9114473462104797     </span>│\n└───────────────────────────┴───────────────────────────┘\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Accuracy with mish activation\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Testing: |          | 0/? [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9dfaa5faa8544bf90114ff0b289fd61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9136841893196106    \u001b[0m\u001b[35m \u001b[0m│\n└───────────────────────────┴───────────────────────────┘\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9136841893196106     </span>│\n└───────────────────────────┴───────────────────────────┘\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Accuracy with ghf activation\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Testing: |          | 0/? [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b012784e41641d9aac3938922c2c705"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9107894897460938    \u001b[0m\u001b[35m \u001b[0m│\n└───────────────────────────┴───────────────────────────┘\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9107894897460938     </span>│\n└───────────────────────────┴───────────────────────────┘\n</pre>\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    }
  ]
}